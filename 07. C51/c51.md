# C51
강화학습의 Q-learning에 distributinal 관점을 적용한것
- =위에 D가 있는것은 좌항과 우항이 같은 분포를 갖는다는 의미

## Contraction of the policy evaluation Bellman operator
- 벨만 오퍼레이터란?

- 벨만 오퍼레이터의 Contraction이란?
   + 벨만 오퍼레이터는 contraction인데, 이것은 벨만 오퍼레이터가 특정 값으로 수렴하는것을 보장해준다.
   즉, 기대 벨만 오퍼레이터를 통해 다음과 같은 표현이 가능
    > $lim_{k->\ingi}$
- Wasserstein Metric?
    Distiribution 사이의 거리를 구하는 방식
    
**고정된 정책이 주어졌을때, Distributional 벨만 오퍼레이터가 수렴**  
  
## Instability in the control setting
policy evaluation과 다르게 벨만 최적화 방정식의 distributional version은 불안정하다.
Distri

## Better approximations
이전에 소개된 내용들은 적용하는데 어려움이 있고,
알고리즘적 관점에

## Settiing
기존에 기대값을 distributional로 변경

- 확률 벡터: 벡터안의 값들이 확률 값일때, 확률 벡터라 한다.
    + 확률 벡터도 확률 분포로 볼 수 있으며, 누적 분포 함수로 볼 수 있다.
    + 
                   
#                                                                                                              
                                                                                                                                